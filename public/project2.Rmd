---
title: "SDS 348 Project 2"
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))
```

## Taylor Wolfenberger (tw25848)
# Introduction

For this project, I have chosen to utilize the merged dataset that I created in Project 1. The dataset describes various natality measures and infant mortality rates for two races, namely, black and white. 
The variables in the dataset include "Year", "Race", "Live Births", "Birth Rate", "Fertility Rate", and "Infant Mortality Rate." The "Year" variable ranges from 1960-2012; these were the years over which the data was collected. The "Race" variable is limited to black and white races. "Live births" denotes the total number of babies born alive each year. "Fertility rate" is defined as the number of births per 1000 women of reproductive age (15-44), and "birth rate" is the number of live births per 1000 women in the total population per year (without taking particular age groups into account). "Infant Mortality Rate" is the number of deaths under one year of age per 1000 live births in a given year. There are a total of 104 observations in the dataset.

```{R}
library(tidyverse)
#Loading in the datasets
InfMortality<-read.csv("~/Downloads/InfantMortalityByRace.csv")
BWNatality<-read.csv("~/Downloads/BWNatality.csv")
#Merging the datasets together, as in Project 1
fulldataset<-inner_join(BWNatality, InfMortality, by=c("Year", "Race"))%>%na.omit()

### MANOVA - Seeing if any numeric variables (-Year) show a mean difference across levels of Race
man1<-manova(cbind(Live.Births,Birth.Rate,Fertility.Rate,Infant.Mortality.Rate)~Race, data=fulldataset)
summary(man1)
#Since overall MANOVA is significant, follow-up one-way ANOVAs are performed
summary.aov(man1) #getting univariate ANOVAs from MANOVA object
#Individual post-hoc t-tests (to determine which groups differ)
pairwise.t.test(fulldataset$Live.Births, fulldataset$Race, p.adj = "none")
pairwise.t.test(fulldataset$Birth.Rate, fulldataset$Race, p.adj = "none")
pairwise.t.test(fulldataset$Fertility.Rate, fulldataset$Race, p.adj = "none")
pairwise.t.test(fulldataset$Infant.Mortality.Rate, fulldataset$Race, p.adj = "none")
#Calculating the probability of at least one Type I error (9 p-values were given)
1-(0.95^9)
#Finding the Bonferroni-adjusted significance level
0.05/9

### Checking assumptions
#Testing for multivariate normality of dependent variables
library(mvtnorm)
library(ggExtra)
fulldataset2<-fulldataset%>%mutate_if(is.numeric, scale)
#Multivariate normality of Infant Mortality Rate + Fertility Rate - already, we fail the multivariate normality test
ggplot(fulldataset, aes(x = Infant.Mortality.Rate, y = Fertility.Rate))+geom_point(alpha = .5)+geom_density_2d(h=2) + coord_fixed()+facet_wrap(~Race)+ggtitle("Assessing Multivariate Normality")
#Eyeballing homogeneity of covariances - difficult to tell, but they seem quite different
covmats<-fulldataset%>%group_by(Race)%>%do(covs=cov(.[3:6]))
for(i in 1:3){print(as.character(covmats$Race[i])); print(covmats$covs[i])}
```

A MANOVA was performed in order to determine whether any of the variables (Live Births, Birth Rate, Fertility Rate, and/or Infant Mortality Rate) show a mean difference across levels of Race (Black or White). The null hypothesis predicted that the means of the groups would be equal for each variable.

The overall MANOVA was found to be statistically significant, so univariate ANOVAs were run in order to assess the responses that showed a mean difference across groups. In addition, post-hoc t-tests were run as well in order to determine which groups differed specifically.
A total of 9 tests were performed above. The probability that at least one Type I Error was committed is 0.3697506. The bonferroni-adjusted significance level was found to be 0.0056. Based on this adjustment, nothing changed, as ALL tests were found to be statistically significant, with p-values much smaller than 0.0056. The implication of this is that Number of Live Births, Birth Rate, Fertility Rate, and Infant Mortality Rate all differ in a statistically significant manner between Black and White races. The means of each variable differ across race.

MANOVA assumptions include: 1) Random samples, independent observations, 2) Multivariate normality of dependent variables, 3) Homogeneity of within-group covariance matrices, 4) Linear relationships among dependent variables, 5) No extreme univariate or multivariate outliers, and 6) No multicollinearity. 

Even the assumption of random samples is unlikely to be met; though the births are all recorded as separate events, this dataset pulls from ALL recorded birth records from the year 1960 onward, and thus it is not a random sample. In addition, many of the dependent variables are likely correlated with one another (for instance, a higher Fertility Rate likely leads to a higher Birth Rate, etc.), which violates Assumption 4 regarding linear relationships among the variables. Lastly, there are likely to be some strong outliers. For instance, prior to the 1970s, birth control was not legalized for all U.S. citizens (Source 4). In Project 1, it was found that after this time period, there was a sharp decline in both birth rate and fertility rate. Therefore, there are likely to be outliers (with very high birth rates and fertility rates) prior to the legalization of birth control. In terms of formal analysis; I began to assess the assumption of multivariate normality by making a multivariate plot of Infant Mortality Rate vs. Fertility Rate. Even this initial test failed the multivariate normality assumption. In addition, I eyeballed the homogeneity of covariances, and they differed drastically as well.

Based on the above, I determined that the assumptions for a MANOVA are likely not properly met. 

# Randomization Test
```{R}
### RANDOMIZATION TEST
#Plot of the distributions of Fertility Rate (by Race)
ggplot(fulldataset,aes(Fertility.Rate,fill=Race))+geom_histogram(bins=6.5)+facet_wrap(~Race,ncol=2)+theme(legend.position="none")+ggtitle("Distributions of Fertility Rate by Race")
#Calculating the actual observed mean difference
fulldataset%>%group_by(Race)%>%summarize(means=mean(Fertility.Rate))%>%summarize(`mean_diff:`=diff(means))

#Performing a permutation (scrambling any association between Fertility Rate and Race)
set.seed(12345)
head(perm1<-data.frame(Fertility.Rate=fulldataset$Fertility.Rate,Race=sample(fulldataset$Race)))
perm1%>%group_by(Race)%>%summarize(means=mean(Fertility.Rate))%>%summarize(`mean_diff:`=diff(means))

#Repeat 5000 times 
set.seed(12345)
rand_dist<-vector()
for(i in 1:5000){
new<-data.frame(Fertility.Rate=sample(fulldataset$Fertility.Rate),Race=fulldataset$Race) 
rand_dist[i]<-mean(new[new$Race=="Black",]$Fertility.Rate)-mean(new[new$Race=="White",]$Fertility.Rate)}

#Finding the mean fertility rate for each race POST-PERMUTATION
new%>%group_by(Race)%>%summarize(mean(Fertility.Rate))
#Plot to visualize the distribution and test statistic 
{hist(rand_dist,main="",ylab=""); abline(v = c(-14.70281,14.70281), col="red")}
#Computing two-tailed p-value
mean(rand_dist>14.70281 | rand_dist< -14.70281)
#Performing an Independent Samples T-test for comparison
t.test(data=fulldataset,Fertility.Rate~Race)
```
Here, a randomization test was performed in order to determine whether or not there is a statistically significant difference in the mean Fertility Rate between women of Black and White races. The null hypothesis is that the true difference in mean Fertility Rate between Black and White women is 0. The alternative hypothesis that there is a statistically significant difference in the mean Fertility Rate of Black and White women. 

A permutation was performed in which I scrambled the association between Race and Fertility Rate. I then repeated this process 5000 times and computed a two-tailed p-value. After performing the permutation, the new mean difference was 0.158. This is much closer to 0 than the original/true mean difference of -14.70281.

The results of the randomization test indicate a p-value of 0. This corresponds to the probability of observing a mean difference as extreme as the one observed in the original data under this new randomized distribution. There are 0 mean differences that are more extreme than the actual value of +/-14.70281. Since p = 0 is less than p = 0.05, the null hypothesis can be rejected, and it can be stated that there is a significant difference in mean Fertility Rate between Black and White women. If the null hypothesis were true, and there was no mean difference in the Fertility Rates of Black and White women, it would be very rare to obtain a true mean difference as large as the one I computed (+/-14.70281). In the plot that depicts the distribution of mean differences (after the association between Race and Fertility Rate was scrambled), the true mean difference of +/-14.70281 is seen on the plot as a vertical red line. In some iterations of the permutation, the true mean difference is so far off from those generated post-permutation that it cannot even be seen.

A Welch's t-test was also run as a basis of comparison. The randomization test does agree with the t-test in that both p-values are < 0.05, thus deeming the difference in means statistically significant & allowing us to reject the null hypothesis. The p-value was slightly different in the parametric t-test; however, both were below 0.05, so the conclusion remains the same.

# Linear Regression Model
```{R}
#Loading packages
library(lmtest)
library(sandwich)
library(ggplot2)
#First, mean-centering the Fertility Rate variable
fulldataset$Fertility.Rate.c <- fulldataset$Fertility.Rate-mean(fulldataset$Fertility.Rate, na.rm=T)

### LINEAR REGRESSION, predicting Birth Rate from Fertility Rate and Race (and their interaction)
fit<-lm(Birth.Rate~Fertility.Rate.c+Race+Fertility.Rate.c:Race, data=fulldataset)
summary(fit)
#Plotting the regression using ggplot
fulldataset%>%ggplot(aes(Fertility.Rate.c,Birth.Rate,color=Race))+geom_point()+geom_smooth(method = 'lm',se=F)+ggtitle("Linear Relationship Between Birth Rate and Fertility Rate + Race")
#R-squared value(s)
summary(fit)$r.sq
summary(fit)$adj.r.sq

#Checking assumptions of linearity, normality, and homoskedasticity
##Checking homoskedasticity using Breuch-Pagan test (null hypothesis is homoskedasticity) - have to reject the null due to p-value < 0.05. We have heteroskedastic data and thus must use robust SEs
bptest(fit)
#Saving residuals as an object
resids<-fit$residuals
##Assessing normality
ggplot()+geom_histogram(aes(resids),bins=10) #looks relatively normal
#Formally testing normality - null hypothesis is that the true distribution is normal. Since the p-value is > 0.05, we do not reject the null (data is normal)
ks.test(resids, "pnorm", mean=0, sd(resids))
ggplot()+geom_qq(aes(sample=resids))+geom_qq_line(aes(sample=resids)) #Checking linearity - appears relatively linear
ggplot(fulldataset, aes(Fertility.Rate.c,Birth.Rate))+geom_point(alpha=.3)

#Computing robust SEs
coeftest(fit, vcov = vcovHC(fit))

##BOOTSTRAPPED SEs
#Sampling rows from dataset with replacement
set.seed(12345)
boot_dat<- sample_frac(fulldataset, replace=T)
# repeat 5000 times
samp_distn<-replicate(5000, {boot_dat <- sample_frac(fulldataset, replace=T) #bootstrapping data
fit2 <- lm(Birth.Rate~Fertility.Rate.c+Race+Fertility.Rate.c:Race, data=boot_dat) 
  coef(fit2) #save coefs
})
## Estimated SEs
samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)
```

Full model: Birth Rate = 18.96 + 0.1765(Fertility.Rate.c) - 2.624(RaceWhite) - 0.0074(Fertility.Rate.c:RaceWhite)

Here, a linear regression model was run in order to predict Birth Rate from Race and Fertility Rate (and their interaction). Fertility Rate was mean-centered first.

The Intercept indicates that the predicted Birth Rate for a Black woman with an average Fertility Rate is 18.96.

The Fertility.Rate.c coefficient indicates that for every 1-unit increase in Fertility Rate, Birth Rate goes up by 0.1765 units for Black women (the reference group).

The RaceWhite coefficient indicates the slope decrease in Birth Rate for White women of an average Fertility Rate, as opposed to the reference group of Black women. For people with an average Fertility Rate, White women have an average/predicted Birth Rate that is 2.624 lower than Black women.

The Fertility.Rate.c:RaceWhite coefficient indicates that the slope for Fertility Rate on Birth Rate is 0.0074 lower for White women compared to Black women.

When the assumptions were assessed, it was found that the data was normal (via the appearance of the histogram + the Kolmogorov-Smirnov test, which produced a p-value of 0.3819). Since the p-value was not < 0.05, we could not reject the null hypothesis of normality. The data also appeared relatively linear, which was assessed by eyeballing a plot of Fertility.Rate.c vs. Birth.Rate. However, the data did not pass the assumption of homoskedasticity; the Breusch-Pagan test produced a p-value of 0.0003114, and since this p is < 0.05, we must reject the null of homoskedasticity. We have heteroskedastic data. Thus, robust SEs were computed as well.

The original SEs are as follows: Intercept SE was 0.145, Fertility Rate SE was 0.006536, RaceWhite SE was 0.207529, and Fertility.Rate.c:RaceWhite SE was 0.011770. After computing robust SEs, the new values were: Intercept SE of 0.181, Fertility Rate SE of 0.0064399, RaceWhite SE of	0.2011275, and Fertility.Rate.c:RaceWhite SE of 0.0080222. As you can see, the SEs are virtually unchanged; however, the interaction model SE has decreased a bit. We aren't taking much of a penalty (despite having heteroskedastic data) since the SEs are virtually unchanged. 

The results remain the same: everything is significant except for the interaction of Race and Fertility Rate. Both Fertility Rate and Race are significantly associated with Birth Rate (p-values: <2e-16). However, the interaction between Fertility Rate and Race was not deemed statistically significant (p-value: 0.532). According to the R-squared value given by the Linear Regression, my model explains 0.947 (94.7%) of the variation in the outcome. The adjusted R-squared value is slightly different at 0.945; this includes a penalty for each extra explanatory variable.

With bootstrapped SEs, the Intercept SE was 0.1796, Fertility Rate SE was 0.0072, RaceWhite SE was 0.198, and the Fertility.Rate.c:RaceWhite SE was 0.0087. 
Compared to the original SEs, the bootstrapped SEs for Intercept and Fertility Rate are a bit higher, but the original SEs for RaceWhite and Fertility.Rate.c:RaceWhite are bit higher than the bootstrapped SEs. Compared to the robust SEs, the bootstrapped SEs for Fertility Rate and Fertility.Rate.c:RaceWhite are a bit higher, but the robust SEs for Intercept and RaceWhite are a bit higher than the bootstrapped SEs. Overall though, they are not drastically different at all. Between the original and robust SEs, the p-values for Intercept, Fertility.Rate.c, and RaceWhite did not change at all really; however, the p-value for the Fertility.Rate.c:RaceWhite interaction decreased in the robust SE (from p = 0.532 to 0.3599). This makes sense, as the SE decreased most drastically here. The general trend is that as SEs decrease, the p-values decrease as well.

# Logistic Regression
```{R}
#Creating binary categorical variable; where Black = 1 and White = 0
fulldataset<-fulldataset%>%mutate(y=ifelse(Race=="Black",1,0))

### LOGISTIC REGRESSION
set.seed(1234)
fit3<-glm(y~Infant.Mortality.Rate+Birth.Rate,data=fulldataset,family=binomial(link="logit"))
coeftest(fit3)
#Exponentiating coefficients for better interpretation
exp(coef(fit3))
#Generating probabilities
fulldataset$prob<-predict(fit3,type="response")
prob<-predict(fit3,type="response")

#Confusion matrix
table(predict=as.numeric(prob>.5),truth=fulldataset$y)%>%addmargins
#Computing sensitivity (TPR)
33/50
#Computing specificity (TNR)
48/54
#Computing accuracy
(33+48)/104
#Computing recall (PPV)
33/39

#Plotting density of log-odds by Race
data<-fulldataset
data$y<-as.factor(data$y)
data$logit<-predict(fit3,type="link") #get predicted logit scores (logodds)
data%>%ggplot()+geom_density(aes(logit,color=Race,fill=Race), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("predictor (logit)")

#Making an ROC curve
library(plotROC)
ROCplot<-ggplot(fulldataset)+geom_roc(aes(d=y,m=prob), n.cuts=0)
ROCplot
#Computing AUC from the ROC curve
calc_auc(ROCplot)

#10-fold CV 
#First, inputting class_diag function...
class_diag<-function(probs,truth){
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}
#End class_diag function

##Begin code for 10-fold CV
library(boot); library(tidyverse); library(lmtest)
set.seed(1234)
k=10
data1<-fulldataset[sample(nrow(fulldataset)),] #put dataset in random order
folds<-cut(seq(1:nrow(fulldataset)),breaks=k,labels=F) #create folds

diags<-NULL
for(i in 1:k){          # FOR EACH OF 10 FOLDS
train<-data1[folds!=i,] # CREATE TRAINING SET
test<-data1[folds==i,]  # CREATE TESTING SET
  
truth<-test$y

fit3<-glm(y~Infant.Mortality.Rate+Birth.Rate, data=train, family="binomial")
probs<-predict(fit3,newdata = test,type="response")  
diags<-rbind(diags,class_diag(probs,truth)) #CV DIAGNOSTICS FOR EACH FOLD
}

summarize_all(diags,mean) #AVERAGE THE DIAGNOSTICS ACROSS THE 10 FOLDS
```
A logistic regression was performed in order to predict Race (Black (1) or White (0)) from Infant Mortality Rate and Birth Rate.

The exponentiated intercept coefficient (0.0000757) depicts the predicted odds of the woman being Black when Birth Rate and Infant Mortality Rate = 0.

The exponentiated Birth Rate coefficient (1.759) indicates that when controlling for Infant Mortality Rate, for every 1 unit increase in Birth Rate, the odds of the woman being Black are multiplied by 1.759.
The Infant Mortality Rate coefficient (0.981) indicates that when controlling for Birth Rate, for every 1 unit increase in Infant Mortality Rate, the odds of the woman being Black are multiplied by 0.981.
Per the confusion matrix and logistic regression model, accuracy was 0.779, sensitivity (TPR) was 0.66, specificity (TNR) was 0.889, and recall (PPV) was 0.846. These are the same numbers that were provided by the logistic regression model as well.
The AUC of the logistic regression was 0.8933. This was considered "Good", almost "Great," and indicates that this model predicts pretty well overall. The AUC can be interpreted as the probability that a randomly selected person that is Black has a higher predicted probability than a randomly selected person that is White. This makes sense, as the Race "Black" was assigned 1 in the binary categorical variable, while the Race "White" was assigned 0.

After the 10-fold CV was performed, the out-of-sample accuracy was 0.77, sensitivity was 0.727, and recall was 0.802. These numbers are not drastically different than those provided by the logistic regression. In addition, the new AUC is 0.923. This indicates that this model is predicting a bit better out-of-sample than the original logistic regression, whose AUC was 0.8933.

# Lasso Regression
```{R}
#Turning the data into matrices for LASSO
x<-fulldataset%>%select(Live.Births,Birth.Rate,Fertility.Rate,Infant.Mortality.Rate)%>%as.matrix
y<-as.matrix(fulldataset$y)

### LASSO; predicting Race (y, where Black = 1 and White = 0) from Live Births, Birth Rate, Fertility Rate, and Infant Mortality Rate - Result is that only the Live Births variable is retained
library(glmnet)
set.seed(1234)
cv.lasso1<-cv.glmnet(x,y,family="binomial")
lasso1<-glmnet(x,y,family="binomial",lambda=cv.lasso1$lambda.1se)
coef(lasso1)

##Begin code for 10-fold CV
library(boot); library(tidyverse); library(lmtest)
set.seed(1234)
k=10

data1<-fulldataset[sample(nrow(fulldataset)),] #put dataset in random order
folds<-cut(seq(1:nrow(fulldataset)),breaks=k,labels=F) #create folds

diags<-NULL
for(i in 1:k){          # FOR EACH OF 10 FOLDS
train<-data1[folds!=i,] # CREATE TRAINING SET
test<-data1[folds==i,]  # CREATE TESTING SET
  
truth<-test$y
  
fit<-glm(y~Live.Births, data=train, family="binomial")
probs<-predict(fit,newdata = test,type="response")  
diags<-rbind(diags,class_diag(probs,truth)) #CV DIAGNOSTICS FOR EACH FOLD
}

summarize_all(diags,mean) #AVERAGE THE DIAGNOSTICS ACROSS THE 10 FOLDS

#
fulldataset%>%group_by(y)%>%summarize(min(Live.Births),max(Live.Births))
```

Only the variable 'Live.Births' was retained by LASSO. A 10-fold CV was then performed, using only the variable Live Births to predict Race, and the class diagnostics resulted in an output of 1 for all factors (accuracy, sensitivity, specificity, ppv, and AUC all = 1). This model's out-of-sample accuracy is even better than that of the Logistic Regression, as it is now 1 (as opposed to 0.77 beforehand). To check the validity of this, a dplyr function was run in order to determine the number of Live Births that formed the minimum and maximum cutoffs for the 0 and 1 groups.

The minimum value for the 0 group is 2551030, while the maximum value for the 1 group is 684336, so there is no overlap between the two groups. As a result of this distinct separation, there are no false positives or false negatives.

In addition, this model's out-of-sample AUC is better than that of the logistic regression. The new AUC is 1, meaning this model is predicting perfectly, while the old out-of-sample AUC for the logistic regression was 0.923. The model's predicting power has gone from 'great' to 'perfect' essentially! 

# Works Cited

Important sources that were utilized throughout the project are as follows:

(1) 'BWNatality' dataset obtained from: https://data.cdc.gov/NCHS/NCHS-Natality-Measures-for-Females-by-Race-and-His/89yk-m38d/data

(2) 'InfMortality' dataset obtained from: https://data.cdc.gov/NCHS/NCHS-Infant-Mortality-Rates-by-Race-United-States-/ddsk-zebd

(3) NCHS information and definitions for natality measures from:
https://www.cdc.gov/nchs/nvss/births.htm?CDC_AA_refVal=https%3A%2F%2Fwww.cdc.gov%2Fnchs%2Fbirths.htm 

(4) Information on the history of birth control legalization in the U.S.: https://www.ourbodiesourselves.org/book-excerpts/health-article/a-brief-history-of-birth-control/ 
